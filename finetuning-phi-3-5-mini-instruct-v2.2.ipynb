{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-01T20:44:12.087685Z","iopub.execute_input":"2024-10-01T20:44:12.088496Z","iopub.status.idle":"2024-10-01T20:44:17.548627Z","shell.execute_reply.started":"2024-10-01T20:44:12.088462Z","shell.execute_reply":"2024-10-01T20:44:17.547722Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:44:17.550245Z","iopub.execute_input":"2024-10-01T20:44:17.550634Z","iopub.status.idle":"2024-10-01T20:44:17.612602Z","shell.execute_reply.started":"2024-10-01T20:44:17.550599Z","shell.execute_reply":"2024-10-01T20:44:17.611627Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:44:17.613665Z","iopub.execute_input":"2024-10-01T20:44:17.613998Z","iopub.status.idle":"2024-10-01T20:44:18.769521Z","shell.execute_reply.started":"2024-10-01T20:44:17.613963Z","shell.execute_reply":"2024-10-01T20:44:18.768369Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Tue Oct  1 20:44:18 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   42C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   41C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\ntoken = \"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\"\nlogin(token)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:44:18.772245Z","iopub.execute_input":"2024-10-01T20:44:18.772597Z","iopub.status.idle":"2024-10-01T20:44:19.466500Z","shell.execute_reply.started":"2024-10-01T20:44:18.772555Z","shell.execute_reply":"2024-10-01T20:44:19.465466Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install datasets\n!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n!pip install -q -U git+https://github.com/lvwerra/trl.git","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:44:19.467733Z","iopub.execute_input":"2024-10-01T20:44:19.468746Z","iopub.status.idle":"2024-10-01T20:46:07.711205Z","shell.execute_reply.started":"2024-10-01T20:44:19.468710Z","shell.execute_reply":"2024-10-01T20:46:07.709926Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"0xayman/function_calling_dataset\")\nds","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:46:07.713082Z","iopub.execute_input":"2024-10-01T20:46:07.713536Z","iopub.status.idle":"2024-10-01T20:46:13.403551Z","shell.execute_reply.started":"2024-10-01T20:46:07.713489Z","shell.execute_reply":"2024-10-01T20:46:13.402542Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/606 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe02ba17fa35420fa7aa5318398ee3fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/11.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f18a7d6d31a4414b85110fb775749755"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/1.45M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5a107f33e9a44bfae48514756eb3526"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/1.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8951dd471da4547a48b75db313cd318"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/22768 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac7caa8ca65247ae9f477e8d7bd2f7d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2846 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a99d81f83ad4dd28f4af06966416afe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/2847 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab3523ae29c64fc1af80eef148f0c6d3"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'query', 'answers', 'tools'],\n        num_rows: 22768\n    })\n    test: Dataset({\n        features: ['id', 'query', 'answers', 'tools'],\n        num_rows: 2846\n    })\n    dev: Dataset({\n        features: ['id', 'query', 'answers', 'tools'],\n        num_rows: 2847\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import json","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:46:13.404795Z","iopub.execute_input":"2024-10-01T20:46:13.405487Z","iopub.status.idle":"2024-10-01T20:46:13.409832Z","shell.execute_reply.started":"2024-10-01T20:46:13.405441Z","shell.execute_reply":"2024-10-01T20:46:13.408888Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def format_instruction(sample):\n    query = sample['query']\n    tools = sample['tools']\n    answers = sample['answers']\n    answers = json.loads(answers)\n\n    assert len(answers) == 1, f\"Each query can only be answered by one function, given {answers}\"\n\n    answer = answers[0]\n\n    prompt = f\"\"\"Your task is to select one of the provided functions to answer the user question.\n    you should select the most relevant function and extract its arguements from the user's question.\\n\n    \n    You have access to the following functions:\\n\n    {tools} \\n\n    \n    Your should follow the following rules:\\n\n    1. Your output should ALWAYS be a valid JSON object.\\n\n    2. Do not make up information.\\n\n    3. You cannot use functions that are not provided for you.\\n\n    4. You should pick up only one function to answer the user question.\\n\n    \n    Your output json object should have the followig fields:\\n\n    1. name: the name of the selected function.\\n\n    2. arguments: an object containing all the function's arguments. the arguments object should contains key-value pairs where is key is the name of the argument and the value is the argument's value extracted from the user query.\\n\n    \n    Begin!\\n\n    \n    Question: {query} \\n\n    Answer: {answer}\n    \"\"\"\n\n    return {\"text\": prompt}","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:46:13.411033Z","iopub.execute_input":"2024-10-01T20:46:13.411940Z","iopub.status.idle":"2024-10-01T20:46:13.421454Z","shell.execute_reply.started":"2024-10-01T20:46:13.411898Z","shell.execute_reply":"2024-10-01T20:46:13.420440Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"formatted_ds = ds.map(format_instruction)\nformatted_ds","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:46:13.422718Z","iopub.execute_input":"2024-10-01T20:46:13.423299Z","iopub.status.idle":"2024-10-01T20:46:16.886530Z","shell.execute_reply.started":"2024-10-01T20:46:13.423254Z","shell.execute_reply":"2024-10-01T20:46:16.885632Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/22768 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1127ac51ad9413492fa747e1961c62b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2846 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e86f3c58727f43f18bc6e27b27436f1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2847 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"764e78ed13bf4432a58543a8081b8c1e"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'query', 'answers', 'tools', 'text'],\n        num_rows: 22768\n    })\n    test: Dataset({\n        features: ['id', 'query', 'answers', 'tools', 'text'],\n        num_rows: 2846\n    })\n    dev: Dataset({\n        features: ['id', 'query', 'answers', 'tools', 'text'],\n        num_rows: 2847\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"model_name = \"microsoft/Phi-3.5-mini-instruct\"","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:46:16.889707Z","iopub.execute_input":"2024-10-01T20:46:16.890333Z","iopub.status.idle":"2024-10-01T20:46:16.894778Z","shell.execute_reply.started":"2024-10-01T20:46:16.890287Z","shell.execute_reply":"2024-10-01T20:46:16.893823Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom peft import LoraConfig, get_peft_model\nfrom transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:46:16.896318Z","iopub.execute_input":"2024-10-01T20:46:16.896704Z","iopub.status.idle":"2024-10-01T20:46:19.987263Z","shell.execute_reply.started":"2024-10-01T20:46:16.896664Z","shell.execute_reply":"2024-10-01T20:46:19.986296Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"129da61a063d42dd9985f11732b278ed"}},"metadata":{}}]},{"cell_type":"code","source":"qlora_config = LoraConfig(\n    r=32,\n    lora_alpha=128,\n    lora_dropout=0.05,\n    target_modules=\"all-linear\",\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:47:14.807296Z","iopub.execute_input":"2024-10-01T20:47:14.808264Z","iopub.status.idle":"2024-10-01T20:47:59.819156Z","shell.execute_reply.started":"2024-10-01T20:47:14.808223Z","shell.execute_reply":"2024-10-01T20:47:59.818370Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/3.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ae9651c803c45e785ec9e1516212a17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3708eaf802644902be6b6e12942c6789"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fba165233e846259b431b29c81f3927"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ed036c1b44e4e118976ee2248465338"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb7c5c297d414733be2a694742ca131e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d653e89325e7419293612010cce092d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebb30f3fb7c84a29be48fd254067e8d5"}},"metadata":{}}]},{"cell_type":"code","source":"print(base_model)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:47:59.820630Z","iopub.execute_input":"2024-10-01T20:47:59.820967Z","iopub.status.idle":"2024-10-01T20:47:59.827954Z","shell.execute_reply.started":"2024-10-01T20:47:59.820934Z","shell.execute_reply":"2024-10-01T20:47:59.827031Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Phi3ForCausalLM(\n  (model): Phi3Model(\n    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x Phi3DecoderLayer(\n        (self_attn): Phi3Attention(\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n          (rotary_emb): Phi3LongRoPEScaledRotaryEmbedding()\n        )\n        (mlp): Phi3MLP(\n          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (activation_fn): SiLU()\n        )\n        (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n        (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): Phi3RMSNorm((3072,), eps=1e-05)\n  )\n  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:47:59.829031Z","iopub.execute_input":"2024-10-01T20:47:59.829320Z","iopub.status.idle":"2024-10-01T20:48:05.157193Z","shell.execute_reply.started":"2024-10-01T20:47:59.829289Z","shell.execute_reply":"2024-10-01T20:48:05.156244Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc113b72d7b94be09931cb3f8adc82b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bbe55810a424d3c9eb4fd6bf2d2b72b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85c2bff45eb04fe18df6392bedab9647"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1117f0654816456798a05692802fa511"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afb521337db94e27880736dc65ef3a2a"}},"metadata":{}}]},{"cell_type":"code","source":"model = get_peft_model(base_model, qlora_config)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:48:05.159057Z","iopub.execute_input":"2024-10-01T20:48:05.159379Z","iopub.status.idle":"2024-10-01T20:48:05.869114Z","shell.execute_reply.started":"2024-10-01T20:48:05.159346Z","shell.execute_reply":"2024-10-01T20:48:05.868255Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:48:05.870442Z","iopub.execute_input":"2024-10-01T20:48:05.870832Z","iopub.status.idle":"2024-10-01T20:48:06.216090Z","shell.execute_reply.started":"2024-10-01T20:48:05.870774Z","shell.execute_reply":"2024-10-01T20:48:06.215225Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"trainable params: 50,331,648 || all params: 3,871,411,200 || trainable%: 1.3001\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"from trl import SFTConfig, SFTTrainer\nfrom transformers import TrainingArguments\n\ntrainer = SFTTrainer(\n  model = model,\n  train_dataset = formatted_ds['train'],\n  eval_dataset = formatted_ds['dev'],\n  peft_config = qlora_config,\n  dataset_text_field = \"text\",\n  max_seq_length = 1024,\n  tokenizer=tokenizer,\n  args=TrainingArguments(\n      per_device_train_batch_size=1,\n      gradient_accumulation_steps=1,\n      warmup_steps=100,\n      max_steps=3000,\n      learning_rate=3e-4,\n      fp16=True,\n      eval_strategy='steps',\n      eval_steps=1000,\n      output_dir='outputs',\n      optim=\"paged_adamw_8bit\",\n  )\n )","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:48:14.792020Z","iopub.execute_input":"2024-10-01T20:48:14.792764Z","iopub.status.idle":"2024-10-01T20:48:57.714513Z","shell.execute_reply.started":"2024-10-01T20:48:14.792725Z","shell.execute_reply":"2024-10-01T20:48:57.713715Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:293: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/22768 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71bfc38c34224ec697eab232124359e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2847 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91b0a4851cdf4ef1a1bd6b45b17dbaa5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:501: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T20:48:57.716238Z","iopub.execute_input":"2024-10-01T20:48:57.716632Z","iopub.status.idle":"2024-10-01T23:23:44.531266Z","shell.execute_reply.started":"2024-10-01T20:48:57.716587Z","shell.execute_reply":"2024-10-01T23:23:44.530355Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241001_204943-85kuvzrq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/aymantarig17-ml/huggingface/runs/85kuvzrq' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/aymantarig17-ml/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/aymantarig17-ml/huggingface' target=\"_blank\">https://wandb.ai/aymantarig17-ml/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/aymantarig17-ml/huggingface/runs/85kuvzrq' target=\"_blank\">https://wandb.ai/aymantarig17-ml/huggingface/runs/85kuvzrq</a>"},"metadata":{}},{"name":"stderr","text":"You are not running the flash-attention implementation, expect numerical differences.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3000/3000 2:33:57, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>0.326200</td>\n      <td>0.324299</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.238300</td>\n      <td>0.264606</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.199700</td>\n      <td>0.219260</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3000, training_loss=0.2786617889404297, metrics={'train_runtime': 9284.9868, 'train_samples_per_second': 0.323, 'train_steps_per_second': 0.323, 'total_flos': 4.205286900425318e+16, 'train_loss': 0.2786617889404297, 'epoch': 0.13176387912860155})"},"metadata":{}}]},{"cell_type":"code","source":"model_to_save = \"0xayman/phi3.5-mini-instruct-fc-v2.2\"\nmodel.push_to_hub(model_to_save)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:25:08.958974Z","iopub.execute_input":"2024-10-01T23:25:08.959613Z","iopub.status.idle":"2024-10-01T23:25:18.382185Z","shell.execute_reply.started":"2024-10-01T23:25:08.959572Z","shell.execute_reply":"2024-10-01T23:25:18.381306Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/201M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"700fb40d19d04d73a877eb85773098d2"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/0xayman/phi3.5-mini-instruct-fc-v2.2/commit/64747e7cc7a265ede8e98f3a81658037da65f3ab', commit_message='Upload model', commit_description='', oid='64747e7cc7a265ede8e98f3a81658037da65f3ab', pr_url=None, repo_url=RepoUrl('https://huggingface.co/0xayman/phi3.5-mini-instruct-fc-v2.2', endpoint='https://huggingface.co', repo_type='model', repo_id='0xayman/phi3.5-mini-instruct-fc-v2.2'), pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.push_to_hub(model_to_save)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:25:18.383542Z","iopub.execute_input":"2024-10-01T23:25:18.383869Z","iopub.status.idle":"2024-10-01T23:25:20.195249Z","shell.execute_reply.started":"2024-10-01T23:25:18.383836Z","shell.execute_reply":"2024-10-01T23:25:20.194293Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04f6955b22af4b51aef6ee141ca56d19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4f096470cba4f5a87512614d003caa4"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/0xayman/phi3.5-mini-instruct-fc-v2.2/commit/f3bc4b2b399db558bd8a4ff177a186205b262185', commit_message='Upload tokenizer', commit_description='', oid='f3bc4b2b399db558bd8a4ff177a186205b262185', pr_url=None, repo_url=RepoUrl('https://huggingface.co/0xayman/phi3.5-mini-instruct-fc-v2.2', endpoint='https://huggingface.co', repo_type='model', repo_id='0xayman/phi3.5-mini-instruct-fc-v2.2'), pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}